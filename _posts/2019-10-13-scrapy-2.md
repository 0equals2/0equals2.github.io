---
layout: post
title: "[Crawling] Scrapy"
excerpt: "스크래피 2"
categories: language
tags: py
---

동적 페이지를 스크래핑하기 위해 selenium + scrapy  활용하기!



1. 시작은 프로젝트를 생성하는 것으로 시작한다. (장고를 생각해보면 쉽다)

2. 결과물을 담을 그릇을 먼저 생성한다 (item.py를 결과 파일을 생각하며 수정한다.)
3. Spider 폴더 안에 새로운 파일을 생성한다. (크롤링을 하는 스파이더 생성)
   1. 상위 폴더의 item.py를 import 해준다.
   2. spider를 정의해준다. (Name 지정, 전체 도메인, 시작 도메인)
   3. Parse() 함수를 정의해준다.
   4. 연결해주는 파이프라인 만들어주기
   5. Settings.py 설정해주기

scrapy crawl <project> 로 스크래피 실행

터미널을 통해 동작을 확인할 수 있다.

