분류 알고리즘

선형성 판별 분석 LDA 선형 경계를 만들고 데이터를 직선에 있다고 가정, 복잡한 모델을 가지고 분류하는 과정에서 정확성이 떨어질 수 있다.

KNN : 가까운 영역 내의 다른 요소들로 해당 성분을 분류해준다. 하지만 학습이라기 보단 학습 데이터를 가지고만 있다. 

단점 게으른 학습 + 속도

텐서플로우를 활용한 로지스틱 회귀를 돌리면 훨씬 성능이 좋아지고 빨라진다.

의사결정트리 : 가장 단순한 classifier 중 하나, 루트부터 적절한 노드를 선택하며 진행하다가 최종 결정을 내리는 모델. 쉽게 이해할 수 있다. 외상치에 민감. 학습해본 적 없는 값은 예측하지 못한다.

배깅 디시젼 트리, 랜덤 포레스트, 에이다 부스트

나이브 베이즈 : 베이지안 룰에 근거한 분류. 일종의 확률 모델로, 가정을 통해 문제를 간단하게 푸는 방법을 제안한다. 만약 데이터의 피쳐가 3개가 있고 각각 바이너리이면 남자인지 여자인지 성인인지 아닌지 키가 큰지 작은지 등의 피쳐를 사용해 사람을 구분해야 한다고 생각해보자. 특성이 10개만 되어도 필요한 데이터의 개수가 1000개가 넘어가게 된다. 일반 베이즈 룰을 사용하게 되면 오버피팅되거나 데이터가 부족해짐. 

이런 문제를 해결 하기 위해 모든 특성들이 서로 비의존하며 같은 분포를 가짐. 당연히 틀린 가정. 하지만 만약 모든 특성이 위와 같다고 하면 우리가 필요한 최소한의 데이터 개수는 feature의 개수에 exponential하게 필요한게 아니라 linear하게 필요하게 된다. 간단한 가정으로 모델의 complexity를 크게 줄일 수 있는 것이다. 때문에 Naïve Bayes 뿐 아니라 많은 모델에서 실제 데이터가 그런 분포를 보이지 않더라도 그 데이터의 분포를 특정한 형태로 가정하여 문제를 간단하게 만드는 기술을 사용한다.

